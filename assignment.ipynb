{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37514a60-b7df-4e26-8be6-800b7a9e9f81",
   "metadata": {},
   "source": [
    "# Hands-On Assignment 5\n",
    "\n",
    "In this assignment, you will practice everything that you have learned so far in an end-to-end setting.\n",
    "You will be provided with a dataset that is **unique to you**, and your task is to perform\n",
    "all the steps from previous assignments to clean, explore, visualize, and analyze your dataset.\n",
    "\n",
    "**Written Portion**: Additionally, you will create a report that describes your process and provides insights about your dataset.\n",
    "Each section that should appear in your report is noted with an orange star (like normal HO tasks).  The report should be  4-6 pages (12 pt font, 1.5 line spacing), and turned in on Canvas as a PDF.\n",
    "\n",
    "The coding aspect for this assignment will be turned in the same was as all other HO's,\n",
    "by submitting this file to the autograder.\n",
    "\n",
    "\n",
    "For this assignment, feel free to make additional functions instead of implementing everything in the provided function.\n",
    "\n",
    "The objective of this assignment is for you to apply and solidify the skills you have learned in previous assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25860737-2a22-4dd3-8f9c-1f8039f1a67f",
   "metadata": {},
   "source": [
    "# Prompt\n",
    "\n",
    "You have graduated from this class, and are a huge success!\n",
    "You landed a job doing data science at some fancy company.\n",
    "\n",
    "You just got a new client with some really interesting problems you get to solve.\n",
    "Unfortunately, because of a big mess-up on their side the data's metadata got corrupted\n",
    "(and the person that used to maintain the data just took a vow of silence and moved to a bog).\n",
    "\n",
    "The only column you are sure about is the `label` column,\n",
    "which contains a numeric label for each row.\n",
    "Aside from that, the client does not know anything about the names, content, or even data types for each column.\n",
    "\n",
    "Your task is to explore, clean, and analyze this data.\n",
    "You should have already received an email with the details on obtaining your unique data.\n",
    "Place it in the same directory as this notebook (and your `local_grader.py` script) and name it `data.txt`.\n",
    "\n",
    "*I know this prompt may sound unrealistic, but I have literally been in a situation exactly like this.\n",
    "I was working at a database startup, and one of our clients gave us data with over 70 columns and more than a million records and told us:\n",
    "\"The person who used to manage the data is no longer working with us, but this was the data they used to make all their decisions.\n",
    "We also lost all the metadata information, like column names.\"\n",
    "...\n",
    "Working in industry is not always glamorous.\n",
    "-Eriq*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb229b6-7448-4d18-8d66-ae09853ed1cd",
   "metadata": {},
   "source": [
    "# Part 0: Explore Your Data\n",
    "\n",
    "Before you start doing things to/with your data, it's always a good idea to load up your data and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb1e1f63-a84d-4452-b52b-1aacaee00148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>col_00</th>\n",
       "      <th>col_01</th>\n",
       "      <th>col_02</th>\n",
       "      <th>col_03</th>\n",
       "      <th>col_04</th>\n",
       "      <th>col_05</th>\n",
       "      <th>col_06</th>\n",
       "      <th>col_07</th>\n",
       "      <th>col_08</th>\n",
       "      <th>col_09</th>\n",
       "      <th>col_10</th>\n",
       "      <th>col_11</th>\n",
       "      <th>col_12</th>\n",
       "      <th>col_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>850 kg</td>\n",
       "      <td>0.8561</td>\n",
       "      <td>applied mathematics</td>\n",
       "      <td>Rabbit</td>\n",
       "      <td>0.4152</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>HAMSTER</td>\n",
       "      <td>0.5747</td>\n",
       "      <td>2026</td>\n",
       "      <td>0.8048</td>\n",
       "      <td>1.6842</td>\n",
       "      <td>670</td>\n",
       "      <td>rat</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1028 kg</td>\n",
       "      <td>0.9142</td>\n",
       "      <td>Games and Playable Media</td>\n",
       "      <td>cat</td>\n",
       "      <td>0.6378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chicken</td>\n",
       "      <td>1.1363</td>\n",
       "      <td>-104</td>\n",
       "      <td>-1.2107</td>\n",
       "      <td>-1.4931</td>\n",
       "      <td>-91</td>\n",
       "      <td>rabbit</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2401 kg</td>\n",
       "      <td>0.373</td>\n",
       "      <td>Bioengineering</td>\n",
       "      <td>dog</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.9553</td>\n",
       "      <td>cat</td>\n",
       "      <td>-0.5059</td>\n",
       "      <td>705</td>\n",
       "      <td>3.0146</td>\n",
       "      <td>1.0999</td>\n",
       "      <td>1550</td>\n",
       "      <td>bird</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>865 kg</td>\n",
       "      <td>1.8129</td>\n",
       "      <td>Computational Media</td>\n",
       "      <td>rabbit</td>\n",
       "      <td>0.9361</td>\n",
       "      <td>-0.0752</td>\n",
       "      <td>hamster</td>\n",
       "      <td>0.5208</td>\n",
       "      <td>410</td>\n",
       "      <td>1.6193</td>\n",
       "      <td>-0.6549</td>\n",
       "      <td>698</td>\n",
       "      <td>rat</td>\n",
       "      <td>-1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1038 kg</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>natural language processing</td>\n",
       "      <td>bird</td>\n",
       "      <td>-0.9037</td>\n",
       "      <td>-0.3321</td>\n",
       "      <td>pig</td>\n",
       "      <td>-0.3035</td>\n",
       "      <td>-691</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>1747</td>\n",
       "      <td>hamster</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>6</td>\n",
       "      <td>614 kg</td>\n",
       "      <td>-0.5986</td>\n",
       "      <td>Electrical Engineering</td>\n",
       "      <td>cat</td>\n",
       "      <td>0.5285</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>guinea pig</td>\n",
       "      <td>1.3322</td>\n",
       "      <td>897</td>\n",
       "      <td>1.6021</td>\n",
       "      <td>0.6096</td>\n",
       "      <td>763</td>\n",
       "      <td>rabbit</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>6</td>\n",
       "      <td>488 kg</td>\n",
       "      <td>0.5701</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>cat</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>-0.0283</td>\n",
       "      <td>rat</td>\n",
       "      <td>-0.0779</td>\n",
       "      <td>-266</td>\n",
       "      <td>0.8431</td>\n",
       "      <td>-0.3589</td>\n",
       "      <td>29</td>\n",
       "      <td>rat</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>2</td>\n",
       "      <td>1849 kg</td>\n",
       "      <td>0.8054</td>\n",
       "      <td>Robotics Engineering</td>\n",
       "      <td>pig</td>\n",
       "      <td>-0.4352</td>\n",
       "      <td>1.2306</td>\n",
       "      <td>ferret</td>\n",
       "      <td>-1.0848</td>\n",
       "      <td>1308</td>\n",
       "      <td>-0.0236</td>\n",
       "      <td>0.9168</td>\n",
       "      <td>-261</td>\n",
       "      <td>fish</td>\n",
       "      <td>1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>3</td>\n",
       "      <td>496 kg</td>\n",
       "      <td>0.6137</td>\n",
       "      <td>Biotechnology</td>\n",
       "      <td>ferret</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.7122</td>\n",
       "      <td>DOG</td>\n",
       "      <td>0.3552</td>\n",
       "      <td>1416</td>\n",
       "      <td>-0.0530</td>\n",
       "      <td>0.7684</td>\n",
       "      <td>771</td>\n",
       "      <td>ferret</td>\n",
       "      <td>-143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>5</td>\n",
       "      <td>1716 kg</td>\n",
       "      <td>0.1899</td>\n",
       "      <td>Technology and Information Management</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>-0.1527</td>\n",
       "      <td>2.0224</td>\n",
       "      <td>pig</td>\n",
       "      <td>0.7081</td>\n",
       "      <td>-494</td>\n",
       "      <td>1.4933</td>\n",
       "      <td>0.3044</td>\n",
       "      <td>751</td>\n",
       "      <td>hamster</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>942 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label   col_00   col_01                                 col_02  col_03  \\\n",
       "0        0   850 kg   0.8561                    applied mathematics  Rabbit   \n",
       "1        6  1028 kg   0.9142               Games and Playable Media     cat   \n",
       "2        1  2401 kg    0.373                         Bioengineering     dog   \n",
       "3        0   865 kg   1.8129                    Computational Media  rabbit   \n",
       "4        5  1038 kg   0.6027            natural language processing    bird   \n",
       "..     ...      ...      ...                                    ...     ...   \n",
       "937      6   614 kg  -0.5986                 Electrical Engineering     cat   \n",
       "938      6   488 kg   0.5701                       Computer Science     cat   \n",
       "939      2  1849 kg   0.8054                   Robotics Engineering     pig   \n",
       "940      3   496 kg   0.6137                          Biotechnology  ferret   \n",
       "941      5  1716 kg   0.1899  Technology and Information Management    BIRD   \n",
       "\n",
       "      col_04  col_05      col_06  col_07 col_08  col_09   col_10 col_11  \\\n",
       "0     0.4152  0.0210     HAMSTER  0.5747   2026  0.8048   1.6842    670   \n",
       "1     0.6378     NaN     chicken  1.1363   -104 -1.2107  -1.4931    -91   \n",
       "2      0.361  0.9553         cat -0.5059    705  3.0146   1.0999   1550   \n",
       "3     0.9361 -0.0752     hamster  0.5208    410  1.6193  -0.6549    698   \n",
       "4    -0.9037 -0.3321         pig -0.3035   -691  0.9618   -0.861   1747   \n",
       "..       ...     ...         ...     ...    ...     ...      ...    ...   \n",
       "937   0.5285  0.1782  guinea pig  1.3322    897  1.6021   0.6096    763   \n",
       "938   0.0154 -0.0283         rat -0.0779   -266  0.8431  -0.3589     29   \n",
       "939  -0.4352  1.2306      ferret -1.0848   1308 -0.0236   0.9168   -261   \n",
       "940    0.258  0.7122         DOG  0.3552   1416 -0.0530   0.7684    771   \n",
       "941  -0.1527  2.0224         pig  0.7081   -494  1.4933   0.3044    751   \n",
       "\n",
       "      col_12 col_13  \n",
       "0        rat    238  \n",
       "1     rabbit   1018  \n",
       "2       bird    303  \n",
       "3        rat  -1114  \n",
       "4    hamster    457  \n",
       "..       ...    ...  \n",
       "937   rabbit    526  \n",
       "938      rat     14  \n",
       "939     fish   1102  \n",
       "940   ferret   -143  \n",
       "941  hamster   1008  \n",
       "\n",
       "[942 rows x 15 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import re\n",
    "import matplotlib.pyplot as pyplot\n",
    "import math\n",
    "import sklearn\n",
    "import scipy\n",
    "\n",
    "# import sklearn.linear_model\n",
    "# import sklearn.neighbors\n",
    "# import sklearn.tree\n",
    "\n",
    "\n",
    "# Modify this to point to your data.\n",
    "unique_data = pandas.read_csv('data.txt', sep = \"\\t\")\n",
    "unique_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7320acb5-49a8-4a94-a044-36bc5056e87c",
   "metadata": {},
   "source": [
    "Don't forget to checkout the column information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a97970b3-3439-44f8-a586-12e2b7e66a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 942 entries, 0 to 941\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   label   942 non-null    int64  \n",
      " 1   col_00  936 non-null    object \n",
      " 2   col_01  934 non-null    object \n",
      " 3   col_02  940 non-null    object \n",
      " 4   col_03  935 non-null    object \n",
      " 5   col_04  933 non-null    object \n",
      " 6   col_05  930 non-null    float64\n",
      " 7   col_06  931 non-null    object \n",
      " 8   col_07  939 non-null    float64\n",
      " 9   col_08  938 non-null    object \n",
      " 10  col_09  936 non-null    float64\n",
      " 11  col_10  933 non-null    object \n",
      " 12  col_11  935 non-null    object \n",
      " 13  col_12  930 non-null    object \n",
      " 14  col_13  938 non-null    object \n",
      "dtypes: float64(3), int64(1), object(11)\n",
      "memory usage: 110.5+ KB\n"
     ]
    }
   ],
   "source": [
    "unique_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4522967-f408-4b57-9f8b-1a7df188ec4f",
   "metadata": {},
   "source": [
    "And any numeric information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b927511d-c9a3-44a1-8cf5-e6257396a92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>col_05</th>\n",
       "      <th>col_07</th>\n",
       "      <th>col_09</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>942.000000</td>\n",
       "      <td>930.000000</td>\n",
       "      <td>939.000000</td>\n",
       "      <td>936.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.969214</td>\n",
       "      <td>0.642005</td>\n",
       "      <td>0.176143</td>\n",
       "      <td>0.438197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.006924</td>\n",
       "      <td>0.854722</td>\n",
       "      <td>0.810569</td>\n",
       "      <td>0.972678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.793300</td>\n",
       "      <td>-3.310000</td>\n",
       "      <td>-2.675400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>-0.379400</td>\n",
       "      <td>-0.218650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.618600</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.428350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.227150</td>\n",
       "      <td>0.705800</td>\n",
       "      <td>1.121725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.043300</td>\n",
       "      <td>2.599400</td>\n",
       "      <td>3.174300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label      col_05      col_07      col_09\n",
       "count  942.000000  930.000000  939.000000  936.000000\n",
       "mean     2.969214    0.642005    0.176143    0.438197\n",
       "std      2.006924    0.854722    0.810569    0.972678\n",
       "min      0.000000   -1.793300   -3.310000   -2.675400\n",
       "25%      1.000000    0.052500   -0.379400   -0.218650\n",
       "50%      3.000000    0.618600    0.165600    0.428350\n",
       "75%      5.000000    1.227150    0.705800    1.121725\n",
       "max      6.000000    3.043300    2.599400    3.174300"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259eb219-6e00-4ac1-b400-417e036f7146",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: Introduction</h4>\n",
    "\n",
    "Briefly describe the dataset you’re given and define the goal of the project and how you approach it.\n",
    "For example, you can present a basic introduction of your data (shape and proposed data types)\n",
    "and your goal is to use these features to predict the label of the response variable.\n",
    "Then you propose a few models that are suitable for this project which will be introduced in the modeling section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4811a58d-2d2b-43db-92e3-3d05c6a24ea3",
   "metadata": {},
   "source": [
    "# Part 1: Data Cleaning\n",
    "\n",
    "As always, we should start with data cleaning.\n",
    "Take what you learned from HO3 to clean up this messy data to a point where it is ready for machine learning algorithms.\n",
    "\n",
    "Some things you may want to do:\n",
    " - Deal with missing/empty values.\n",
    " - Fix numeric columns so that they actually contain numbers.\n",
    " - Remove inconsistencies from columns.\n",
    " - Assign a data type to each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431c9f31-9286-40a6-8816-d6dfd643ab04",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Task 1.A</h4>\n",
    "\n",
    "Complete the following function that takes in a DataFrame and outputs a clean version of the DataFrame.\n",
    "You can assume that the frame has all the same structure as your unique dataset.\n",
    "You can return the same or a new data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "115f8eb6-71ec-4036-80e9-39cd51d67166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Outliers:  {'col_07': [(np.int64(2), np.float64(-3.31))]}\n",
      "5\n",
      "6\n",
      "label\n",
      "col_00\n",
      "col_01\n",
      "col_04\n",
      "col_05\n",
      "col_07\n",
      "col_08\n",
      "col_09\n",
      "col_10\n",
      "col_11\n",
      "col_13\n",
      "7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>col_00</th>\n",
       "      <th>col_01</th>\n",
       "      <th>col_04</th>\n",
       "      <th>col_05</th>\n",
       "      <th>col_07</th>\n",
       "      <th>col_08</th>\n",
       "      <th>col_09</th>\n",
       "      <th>col_10</th>\n",
       "      <th>col_11</th>\n",
       "      <th>...</th>\n",
       "      <th>bird_3</th>\n",
       "      <th>hamster_3</th>\n",
       "      <th>reptile_3</th>\n",
       "      <th>pig_3</th>\n",
       "      <th>guinea pig_3</th>\n",
       "      <th>dog_3</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>fish_3</th>\n",
       "      <th>chicken_3</th>\n",
       "      <th>ferret_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>850</td>\n",
       "      <td>0.8561</td>\n",
       "      <td>0.4152</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.5747</td>\n",
       "      <td>2026</td>\n",
       "      <td>0.8048</td>\n",
       "      <td>1.6842</td>\n",
       "      <td>670</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1028</td>\n",
       "      <td>0.9142</td>\n",
       "      <td>0.6378</td>\n",
       "      <td>0.642005</td>\n",
       "      <td>1.1363</td>\n",
       "      <td>-104</td>\n",
       "      <td>-1.2107</td>\n",
       "      <td>-1.4931</td>\n",
       "      <td>-91</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2401</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.9553</td>\n",
       "      <td>-0.5059</td>\n",
       "      <td>705</td>\n",
       "      <td>3.0146</td>\n",
       "      <td>1.0999</td>\n",
       "      <td>1550</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>865</td>\n",
       "      <td>1.8129</td>\n",
       "      <td>0.9361</td>\n",
       "      <td>-0.0752</td>\n",
       "      <td>0.5208</td>\n",
       "      <td>410</td>\n",
       "      <td>1.6193</td>\n",
       "      <td>-0.6549</td>\n",
       "      <td>698</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1038</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>-0.9037</td>\n",
       "      <td>-0.3321</td>\n",
       "      <td>-0.3035</td>\n",
       "      <td>-691</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>1747</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>6</td>\n",
       "      <td>614</td>\n",
       "      <td>-0.5986</td>\n",
       "      <td>0.5285</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>1.3322</td>\n",
       "      <td>897</td>\n",
       "      <td>1.6021</td>\n",
       "      <td>0.6096</td>\n",
       "      <td>763</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>6</td>\n",
       "      <td>488</td>\n",
       "      <td>0.5701</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>-0.0283</td>\n",
       "      <td>-0.0779</td>\n",
       "      <td>-266</td>\n",
       "      <td>0.8431</td>\n",
       "      <td>-0.3589</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>2</td>\n",
       "      <td>1849</td>\n",
       "      <td>0.8054</td>\n",
       "      <td>-0.4352</td>\n",
       "      <td>1.2306</td>\n",
       "      <td>-1.0848</td>\n",
       "      <td>1308</td>\n",
       "      <td>-0.0236</td>\n",
       "      <td>0.9168</td>\n",
       "      <td>-261</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>3</td>\n",
       "      <td>496</td>\n",
       "      <td>0.6137</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.7122</td>\n",
       "      <td>0.3552</td>\n",
       "      <td>1416</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.7684</td>\n",
       "      <td>771</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>5</td>\n",
       "      <td>1716</td>\n",
       "      <td>0.1899</td>\n",
       "      <td>-0.1527</td>\n",
       "      <td>2.0224</td>\n",
       "      <td>0.7081</td>\n",
       "      <td>-494</td>\n",
       "      <td>1.4933</td>\n",
       "      <td>0.3044</td>\n",
       "      <td>751</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>942 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  col_00  col_01  col_04    col_05  col_07  col_08  col_09  col_10  \\\n",
       "0        0     850  0.8561  0.4152     0.021  0.5747    2026  0.8048  1.6842   \n",
       "1        6    1028  0.9142  0.6378  0.642005  1.1363    -104 -1.2107 -1.4931   \n",
       "2        1    2401   0.373   0.361    0.9553 -0.5059     705  3.0146  1.0999   \n",
       "3        0     865  1.8129  0.9361   -0.0752  0.5208     410  1.6193 -0.6549   \n",
       "4        5    1038  0.6027 -0.9037   -0.3321 -0.3035    -691  0.9618  -0.861   \n",
       "..     ...     ...     ...     ...       ...     ...     ...     ...     ...   \n",
       "937      6     614 -0.5986  0.5285    0.1782  1.3322     897  1.6021  0.6096   \n",
       "938      6     488  0.5701  0.0154   -0.0283 -0.0779    -266  0.8431 -0.3589   \n",
       "939      2    1849  0.8054 -0.4352    1.2306 -1.0848    1308 -0.0236  0.9168   \n",
       "940      3     496  0.6137   0.258    0.7122  0.3552    1416  -0.053  0.7684   \n",
       "941      5    1716  0.1899 -0.1527    2.0224  0.7081    -494  1.4933  0.3044   \n",
       "\n",
       "     col_11  ...  bird_3  hamster_3  reptile_3  pig_3  guinea pig_3  dog_3  \\\n",
       "0       670  ...       0          0          0      0             0      0   \n",
       "1       -91  ...       0          0          0      0             0      0   \n",
       "2      1550  ...       0          0          0      0             0      0   \n",
       "3       698  ...       0          0          0      0             0      0   \n",
       "4      1747  ...       0          0          0      0             0      0   \n",
       "..      ...  ...     ...        ...        ...    ...           ...    ...   \n",
       "937     763  ...       0          0          0      0             0      0   \n",
       "938      29  ...       0          0          0      0             0      0   \n",
       "939    -261  ...       0          0          0      0             0      0   \n",
       "940     771  ...       0          0          0      0             0      0   \n",
       "941     751  ...       0          0          0      0             0      0   \n",
       "\n",
       "     cat_3  fish_3  chicken_3  ferret_3  \n",
       "0        0       0          0         0  \n",
       "1        0       0          0         0  \n",
       "2        0       0          0         0  \n",
       "3        0       0          0         0  \n",
       "4        0       0          0         0  \n",
       "..     ...     ...        ...       ...  \n",
       "937      0       0          0         0  \n",
       "938      0       0          0         0  \n",
       "939      0       0          0         0  \n",
       "940      0       0          0         0  \n",
       "941      0       0          0         0  \n",
       "\n",
       "[942 rows x 63 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solely for surveying to determine best way to handle empty values\n",
    "def print_empty_counts(frame):\n",
    "    # print column counts\n",
    "    for column in frame.columns:\n",
    "        empty_count = frame[column].isna().sum()\n",
    "        print(column, empty_count)\n",
    "\n",
    "    # print row counts\n",
    "    a = [0] * len(frame.columns)\n",
    "    for index, row in frame.iterrows():\n",
    "        empty_count = frame.loc[index].isna().sum()\n",
    "        if empty_count > 0:\n",
    "            a[empty_count] += 1\n",
    "    print(a)\n",
    "\n",
    "\n",
    "# Replaces entries that are the string \"?\" with numpy NaNs\n",
    "def replace_question_marks_with_nans(frame):\n",
    "    for column in frame.columns:\n",
    "        for row_idx in frame.index:\n",
    "            if frame.loc[row_idx, column] == '?':\n",
    "                frame.loc[row_idx, column] = numpy.nan\n",
    "    \n",
    "    return frame\n",
    "\n",
    "# Extracts numbers from strings and casts integer floats to ints\n",
    "def extract_numbers(frame, ignore_columns = []):\n",
    "    for column in frame.columns:\n",
    "        if column in ignore_columns:\n",
    "            continue\n",
    "        if frame.dtypes[column] != 'object':  # skip uniform type columns\n",
    "            continue\n",
    "\n",
    "        # extract numbers from every row in column\n",
    "        for i in frame.index:\n",
    "            entry = frame.loc[i, column]\n",
    "            if pandas.isna(entry):\n",
    "                # value missing\n",
    "                continue\n",
    "            \n",
    "            # replace strings with any number inside\n",
    "            if isinstance(entry, str):\n",
    "                # match numbers\n",
    "                match = re.match(r\"-?\\d+(\\.\\d+)?\", entry)\n",
    "                if not match:\n",
    "                    print(\"Failed to match: \", column, i, entry, match)\n",
    "\n",
    "                # cast match to int or float\n",
    "                number_str = match[0]\n",
    "                if match[1]:  # if decimal found\n",
    "                    entry = numpy.float64(number_str)\n",
    "                else:\n",
    "                    entry = numpy.int64(number_str)\n",
    "                \n",
    "                frame.loc[i, column] = entry\n",
    "    \n",
    "    return frame\n",
    "\n",
    "# Attempts to cast column to its dominant (majority) type.\n",
    "# If the dominant type is str, numbers are discarded\n",
    "# If the type is numerical, strings are discarded and numbers casted.\n",
    "def guess_types(frame):\n",
    "    for column in frame.columns:\n",
    "        # Count types in column\n",
    "        str_count = frame[column].apply(lambda x: isinstance(x, str)).sum()\n",
    "        int_count = frame[column].apply(lambda x: isinstance(x, (int, numpy.integer))).sum()\n",
    "        # needed to shorten line length\n",
    "        is_float = lambda x: isinstance(x, (float, numpy.floating))\n",
    "        is_non_integer = lambda x: not x.is_integer() if is_float(x) else False\n",
    "        float_count = frame[column].apply(lambda x: is_float(x) and is_non_integer(x)).sum()\n",
    "        \n",
    "        # Set col_type to dominant type\n",
    "        col_type = None\n",
    "        total_count = str_count + float_count + int_count\n",
    "        threshold = .9 * total_count\n",
    "        if str_count > threshold:\n",
    "            col_type = str\n",
    "        elif float_count > threshold:\n",
    "            col_type = numpy.float64\n",
    "        elif int_count > threshold:\n",
    "            col_type = numpy.int64\n",
    "\n",
    "        for row in frame.index:\n",
    "            entry = frame.loc[row, column]\n",
    "            if pandas.isna(entry):\n",
    "                continue\n",
    "\n",
    "            # Remove inconsistent or uncastable data types\n",
    "            new_entry = entry\n",
    "            if col_type is str:\n",
    "                if not isinstance(entry, str):\n",
    "                    new_entry = numpy.nan\n",
    "            else:  # float64 or int64\n",
    "                if isinstance(entry, str):\n",
    "                    new_entry = numpy.nan\n",
    "            \n",
    "            frame.loc[row, column] = new_entry\n",
    "\n",
    "        # Set column type\n",
    "        if col_type is str:\n",
    "            frame[column] = frame[column].astype(\"string\")\n",
    "        if col_type is numpy.float64:\n",
    "            frame[column] = frame[column].astype(\"Float64\")\n",
    "        if col_type is numpy.int64:\n",
    "            frame[column] = frame[column].astype(\"Int64\")\n",
    "        \n",
    "    return frame\n",
    "\n",
    "\n",
    "# Finds and returns outliers\n",
    "def find_outliers(frame, deviations, label_column_name):\n",
    "    outliers = dict()\n",
    "    \n",
    "    for column in frame.columns:\n",
    "        if frame[column].dtype == \"string\" or frame[column].dtype == \"object\":\n",
    "            continue\n",
    "        \n",
    "        sumx = 0\n",
    "        sumx2 = 0\n",
    "        n = 0\n",
    "        hasStr = False\n",
    "        for row in frame.index:\n",
    "            entry = frame[column][row]\n",
    "            if pandas.isna(entry):\n",
    "                continue\n",
    "            sumx += entry\n",
    "            sumx2 += entry * entry\n",
    "            n += 1\n",
    "\n",
    "        if hasStr:\n",
    "            continue\n",
    "        \n",
    "        outlier_list = []\n",
    "        \n",
    "        mean = sumx / n\n",
    "        variance = sumx2 / n - mean ** 2\n",
    "        stdev = math.sqrt(variance)\n",
    "        for row in frame.index:\n",
    "            entry = frame[column][row]\n",
    "            if isinstance(entry, int) or isinstance(entry, float):\n",
    "                if abs(entry - mean) > deviations * stdev:\n",
    "                    outlier_list.append((frame[label_column_name][row], entry))\n",
    "\n",
    "        if len(outlier_list) > 0:\n",
    "            outliers[column] = outlier_list\n",
    "    \n",
    "    return outliers\n",
    "\n",
    "\n",
    "def fill_missing_values(frame, ignore_columns = []):\n",
    "    for column in frame.columns:\n",
    "        if column in ignore_columns:\n",
    "            continue\n",
    "\n",
    "        column_type = frame.dtypes[column]\n",
    "        column_mean = frame[column].mean()\n",
    "        if column_type == \"Int64\":\n",
    "            column_mean = round(column_mean)\n",
    "        frame[column] = frame[column].fillna(column_mean)\n",
    "        \n",
    "    return frame\n",
    "\n",
    "\n",
    "# Trims strings and makes them lowercase\n",
    "def normalize_strings(frame):\n",
    "    for column in frame.columns:\n",
    "        if frame.dtypes[column] != \"string\":\n",
    "            print(column)\n",
    "            continue\n",
    "        \n",
    "        frame[column] = frame[column].apply(lambda x: x.strip().lower() if pandas.notna(x) else x)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "\n",
    "# One-hot encodes string columns\n",
    "def one_hot(frame, column_name, suffix = \"\"):\n",
    "    onehotcols = dict()\n",
    "    i = 0\n",
    "    for row in frame.index:\n",
    "        entry = frame.at[row, column_name]\n",
    "        if pandas.isna(entry):\n",
    "            continue\n",
    "        \n",
    "        categories = entry.split(\",\")\n",
    "        for category in categories:\n",
    "            category = category.strip()\n",
    "            \n",
    "            # make sure category isnt empty\n",
    "            if category == \"\":\n",
    "                continue\n",
    "            \n",
    "            if category not in onehotcols:\n",
    "                onehotcols[category + suffix] = [0] * len(frame)\n",
    "            \n",
    "            onehotcols[category + suffix][i] = 1\n",
    "\n",
    "        i += 1\n",
    "        \n",
    "    frame.drop(column_name, axis=1, inplace=True)\n",
    "    frame = pandas.concat([frame, pandas.DataFrame(onehotcols)], axis=1)\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def clean_data(frame):\n",
    "    string_columns = [\"col_02\", \"col_03\", \"col_06\", \"col_12\"]\n",
    "\n",
    "    print(1)\n",
    "    frame = replace_question_marks_with_nans(frame)\n",
    "    print(2)\n",
    "    frame = extract_numbers(frame, ignore_columns = string_columns)\n",
    "    print(3)\n",
    "    frame = guess_types(frame)\n",
    "    print(4)\n",
    "    print(\"Outliers: \", find_outliers(frame, 4.0, 'label'))\n",
    "    print(5)\n",
    "    frame = fill_missing_values(frame, string_columns)\n",
    "    print(6)\n",
    "    frame = normalize_strings(frame)\n",
    "    print(7)\n",
    "    # print(frame[\"col_02\"].unique())\n",
    "    # print(frame[\"col_03\"].unique())\n",
    "    # print(frame[\"col_06\"].unique())\n",
    "    # print(frame[\"col_12\"].unique())\n",
    "    \n",
    "    frame = one_hot(frame, \"col_02\")  # Major\n",
    "    frame = one_hot(frame, \"col_03\", suffix = \"_1\")  # Pets 1\n",
    "    frame = one_hot(frame, \"col_06\", suffix = \"_2\")  # Pets 2\n",
    "    frame = one_hot(frame, \"col_12\", suffix = \"_3\")  # Pets 3\n",
    "    \n",
    "    return frame\n",
    "\n",
    "unique_data = clean_data(unique_data)\n",
    "unique_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c55d30a-550d-46f3-ad3b-c0e49a1b8a10",
   "metadata": {},
   "source": [
    "Now we should also be able to view all the numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f886c77c-0dad-47ae-ab2b-8661ec63f98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 942 entries, 0 to 941\n",
      "Data columns (total 63 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   label                                  942 non-null    Int64  \n",
      " 1   col_00                                 942 non-null    Int64  \n",
      " 2   col_01                                 942 non-null    Float64\n",
      " 3   col_04                                 942 non-null    Float64\n",
      " 4   col_05                                 942 non-null    Float64\n",
      " 5   col_07                                 942 non-null    Float64\n",
      " 6   col_08                                 942 non-null    Int64  \n",
      " 7   col_09                                 942 non-null    Float64\n",
      " 8   col_10                                 942 non-null    Float64\n",
      " 9   col_11                                 942 non-null    Int64  \n",
      " 10  col_13                                 942 non-null    Int64  \n",
      " 11  applied mathematics                    942 non-null    int64  \n",
      " 12  games and playable media               942 non-null    int64  \n",
      " 13  bioengineering                         942 non-null    int64  \n",
      " 14  computational media                    942 non-null    int64  \n",
      " 15  natural language processing            942 non-null    int64  \n",
      " 16  electrical engineering                 942 non-null    int64  \n",
      " 17  data science                           942 non-null    int64  \n",
      " 18  computer engineering                   942 non-null    int64  \n",
      " 19  biotechnology                          942 non-null    int64  \n",
      " 20  computer science                       942 non-null    int64  \n",
      " 21  bioinformatics                         942 non-null    int64  \n",
      " 22  computer game design                   942 non-null    int64  \n",
      " 23  human computer interaction             942 non-null    int64  \n",
      " 24  technology and information management  942 non-null    int64  \n",
      " 25  robotics engineering                   942 non-null    int64  \n",
      " 26  statistics                             942 non-null    int64  \n",
      " 27  rabbit_1                               942 non-null    int64  \n",
      " 28  cat_1                                  942 non-null    int64  \n",
      " 29  dog_1                                  942 non-null    int64  \n",
      " 30  bird_1                                 942 non-null    int64  \n",
      " 31  reptile_1                              942 non-null    int64  \n",
      " 32  guinea pig_1                           942 non-null    int64  \n",
      " 33  chicken_1                              942 non-null    int64  \n",
      " 34  ferret_1                               942 non-null    int64  \n",
      " 35  hamster_1                              942 non-null    int64  \n",
      " 36  rat_1                                  942 non-null    int64  \n",
      " 37  fish_1                                 942 non-null    int64  \n",
      " 38  pig_1                                  942 non-null    int64  \n",
      " 39  hamster_2                              942 non-null    int64  \n",
      " 40  chicken_2                              942 non-null    int64  \n",
      " 41  cat_2                                  942 non-null    int64  \n",
      " 42  pig_2                                  942 non-null    int64  \n",
      " 43  reptile_2                              942 non-null    int64  \n",
      " 44  dog_2                                  942 non-null    int64  \n",
      " 45  rat_2                                  942 non-null    int64  \n",
      " 46  ferret_2                               942 non-null    int64  \n",
      " 47  rabbit_2                               942 non-null    int64  \n",
      " 48  fish_2                                 942 non-null    int64  \n",
      " 49  guinea pig_2                           942 non-null    int64  \n",
      " 50  bird_2                                 942 non-null    int64  \n",
      " 51  rat_3                                  942 non-null    int64  \n",
      " 52  rabbit_3                               942 non-null    int64  \n",
      " 53  bird_3                                 942 non-null    int64  \n",
      " 54  hamster_3                              942 non-null    int64  \n",
      " 55  reptile_3                              942 non-null    int64  \n",
      " 56  pig_3                                  942 non-null    int64  \n",
      " 57  guinea pig_3                           942 non-null    int64  \n",
      " 58  dog_3                                  942 non-null    int64  \n",
      " 59  cat_3                                  942 non-null    int64  \n",
      " 60  fish_3                                 942 non-null    int64  \n",
      " 61  chicken_3                              942 non-null    int64  \n",
      " 62  ferret_3                               942 non-null    int64  \n",
      "dtypes: Float64(6), Int64(5), int64(52)\n",
      "memory usage: 473.9 KB\n"
     ]
    }
   ],
   "source": [
    "unique_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bff37a-7241-4a4a-bc2d-8a30a54826f4",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: Data Cleaning</h4>\n",
    "\n",
    "Describe the steps you took for data cleaning.\n",
    "Why did you do this?\n",
    "Did you have to make some choices along the way? If so, describe them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430a58e3-0ac0-4629-bc72-4a7ba71cf68e",
   "metadata": {},
   "source": [
    "# Part 2: Data Visualization\n",
    "\n",
    "Once you have cleaned up the data, it is time to explore it and find interesting things.\n",
    "Part of this exploration, will be visualizing the data in a way that makes it easier for yourself and others to understand.\n",
    "Use what you have learned in HO1 and HO2 to create some visualizations for your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c220e6d0-202a-4f9e-b5de-0167025ff2ad",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: Data Visualization</h4>\n",
    "\n",
    "Create at least two different visualizations that help describe what you see in your dataset.\n",
    "Include these visualizations in your report along with descriptions of\n",
    "how you created the visualization,\n",
    "what data preparation you had to do for the visualization (aside from the data cleaning in the previous part),\n",
    "and what the visualization tells us about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f52b4772-f871-4d06-956a-1345310f0ca2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'col_02'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'col_02'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# for column in unique_data.columns:\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m#     print(column, unique_data.dtypes[column])\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m#     if unique_data.dtypes[column] == \"string\":\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# plot_counts(unique_data, \"col_06\")  # Pets 2\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# plot_counts(unique_data, \"col_12\")  # Pets 3\u001b[39;00m\n\u001b[32m     29\u001b[39m label_filtered = unique_data[unique_data[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[43mplot_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcol_02\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Majors\u001b[39;00m\n\u001b[32m     31\u001b[39m plot_counts(label_filtered, \u001b[33m\"\u001b[39m\u001b[33mcol_03\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# Pets 1\u001b[39;00m\n\u001b[32m     32\u001b[39m plot_counts(label_filtered, \u001b[33m\"\u001b[39m\u001b[33mcol_06\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# Pets 2\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mplot_counts\u001b[39m\u001b[34m(frame, column)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_counts\u001b[39m(frame, column):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     counts = \u001b[43mframe\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m.value_counts()\n\u001b[32m      3\u001b[39m     pyplot.bar(counts.index, counts.values)\n\u001b[32m      4\u001b[39m     pyplot.xticks(rotation=\u001b[32m90\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'col_02'"
     ]
    }
   ],
   "source": [
    "def plot_counts(frame, column):\n",
    "    counts = frame[column].value_counts()\n",
    "    pyplot.bar(counts.index, counts.values)\n",
    "    pyplot.xticks(rotation=90)\n",
    "    pyplot.title(f\"Frequency of categories in {column}\")\n",
    "    pyplot.xlabel(\"Category\")\n",
    "    pyplot.ylabel(\"Frequency\")\n",
    "    pyplot.show()\n",
    "\n",
    "def plot_hist(frame, column):\n",
    "    pyplot.hist(frame[column], bins=10, edgecolor='black')\n",
    "    pyplot.xlabel(column)\n",
    "    pyplot.ylabel(\"Frequency\")\n",
    "    pyplot.title(f\"Histogram of {column}\")\n",
    "    pyplot.show()\n",
    "\n",
    "# for column in unique_data.columns:\n",
    "#     print(column, unique_data.dtypes[column])\n",
    "#     if unique_data.dtypes[column] == \"string\":\n",
    "#         # plot_bar(unique_data, column)\n",
    "#         continue\n",
    "\n",
    "plot_counts(unique_data, \"label\")\n",
    "# plot_counts(unique_data, \"col_02\")  # Majors\n",
    "# plot_counts(unique_data, \"col_03\")  # Pets 1\n",
    "# plot_counts(unique_data, \"col_06\")  # Pets 2\n",
    "# plot_counts(unique_data, \"col_12\")  # Pets 3\n",
    "\n",
    "label_filtered = unique_data[unique_data[\"label\"] == 0]\n",
    "# plot_counts(label_filtered, \"col_02\")  # Majors\n",
    "# plot_counts(label_filtered, \"col_03\")  # Pets 1\n",
    "# plot_counts(label_filtered, \"col_06\")  # Pets 2\n",
    "# plot_counts(label_filtered, \"col_12\")  # Pets 3\n",
    "\n",
    "# for column in label_filtered.columns:\n",
    "#     coltype = label_filtered.dtypes[column]\n",
    "#     print(coltype)\n",
    "#     if coltype != \"Int64\" and coltype != \"Float64\":\n",
    "#         continue\n",
    "#     plot_hist(label_filtered, column)\n",
    "\n",
    "# for i in range(0, 7): #[0, 1]:  # see: col_04, [0, 1, 3, 5]\n",
    "#     plot_hist(unique_data[unique_data[\"label\"] == i], \"col_04\")\n",
    "# for i in [3, 5]:  # see: col_04, [0, 1, 3, 5]\n",
    "#     plot_hist(unique_data[unique_data[\"label\"] == i], \"col_04\")\n",
    "\n",
    "# plot_xy(frame,  4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1f3fb1-16c8-4079-9bdf-b8a8db02370a",
   "metadata": {},
   "source": [
    "# Part 3: Modeling\n",
    "\n",
    "Now that you have a good grasp of your clean data,\n",
    "it is time to do some machine learning!\n",
    "(Technically all our previous steps were also machine learning,\n",
    "but now we get to use classifiers!)\n",
    "\n",
    "Use the skills you developed to select **three** classifiers and implement them on your data.\n",
    "For example, you can narrow down your choices to three classifiers which may include:\n",
    "- Logistic regression\n",
    "- K-nearest neighbors\n",
    "- Decision tree\n",
    "- Or others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924e896-2c73-4c83-89b4-54c6a8423e69",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Task 3.A</h4>\n",
    "\n",
    "Complete the following function that takes in no parameters,\n",
    "and returns a list with **three** untrained classifiers you are going to explore in this assignment.\n",
    "This method may set parameters/options for the classifiers, but should not do any training/fitting.\n",
    "\n",
    "For example, if you wanted to use logistic regression,\n",
    "then **one** of your list items may be:\n",
    "```\n",
    "sklearn.linear_model.LogisticRegression()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce3b3a5-91a3-4c7a-85f1-84b266a5a781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifiers():\n",
    "    return [\n",
    "        sklearn.linear_model.LogisticRegression(),\n",
    "        sklearn.neighbors.KNeighborsClassifier(n_neighbors = 10),\n",
    "        sklearn.tree.DecisionTreeClassifier()\n",
    "    ]\n",
    "\n",
    "my_classifiers = create_classifiers()\n",
    "my_classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c115a2-9b07-438a-bd5f-682c22078ca2",
   "metadata": {},
   "source": [
    "Now that we have some classifiers, we can see how they perform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7795bb4a-4545-47fc-9c77-4861a4820333",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Task 3.B</h4>\n",
    "\n",
    "Complete the following function that takes in an untrained classifier, a DataFrame, and a number of folds.\n",
    "This function should run k-fold cross validation with the classifier and the data,\n",
    "and return a list with the accuracy of each run of cross validation.\n",
    "You can assume that the frame has the column `label` and the rest of the columns can be considered clean numeric features.\n",
    "\n",
    "Note that you may have to break your frame into features and labels to do this.\n",
    "Do not change the passed-in frame (make copies instead).\n",
    "\n",
    "If you are getting any `ConvergenceWarning`s you may either ignore them,\n",
    "or try and address them\n",
    "(they will not affect your autograder score, but may be something to discuss in the written portion of this assignment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770c5ea-18fe-41f3-ad5b-e72f463be876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_fold_validation(classifier, frame, folds):\n",
    "    y = frame[\"label\"]\n",
    "    x = frame.drop(columns = \"label\")  # creates a copy\n",
    "\n",
    "    # scikit-learn functions\n",
    "    # on KFold: use random_state parameter for reproducibility\n",
    "    k_fold = sklearn.model_selection.KFold(n_splits = folds, shuffle = True)\n",
    "    accuracy_scores = sklearn.model_selection.cross_val_score(classifier, x, y, cv = k_fold)\n",
    "    \n",
    "    return list(accuracy_scores)\n",
    "\n",
    "\n",
    "my_classifiers_scores = []\n",
    "for classifier in my_classifiers:\n",
    "    accuracy_scores = cross_fold_validation(classifier, unique_data, 5)\n",
    "    my_classifiers_scores.append(accuracy_scores)\n",
    "    print(\"Classifier: %s, Accuracy: %s.\" % (type(classifier).__name__, accuracy_scores))\n",
    "\n",
    "    print(\"Mean Accuracy: \", sum(accuracy_scores) / len(accuracy_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c8552-9d78-4393-a9e8-f1e583e0e93e",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Task 3.C</h4>\n",
    "\n",
    "Complete the following function that takes in two equally-sized lists of numbers and a p-value.\n",
    "This function should compute whether there is a statistical significance between\n",
    "these two lists of numbers using a [Student's t-test](https://en.wikipedia.org/wiki/Student%27s_t-test)\n",
    "at the given p-value.\n",
    "Return `True` if there is a statistical significance, and `False` otherwise.\n",
    "Hint: If you wish, you may use the `ttest_ind()` [method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html) provided in the scipy package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed3c9500-b91a-400a-8f1a-4f1e971fca26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression vs KNeighborsClassifier: True\n",
      "LogisticRegression vs DecisionTreeClassifier: True\n",
      "KNeighborsClassifier vs DecisionTreeClassifier: True\n"
     ]
    }
   ],
   "source": [
    "def significance_test(a_values, b_values, p_value):\n",
    "    # did not adjust variance, so set equal_var to false\n",
    "    t_statistic, p = scipy.stats.ttest_ind(a_values, b_values, equal_var = False)\n",
    "    return p < p_value\n",
    "\n",
    "for i in range(len(my_classifiers)):\n",
    "    for j in range(i + 1, len(my_classifiers)):\n",
    "        significant = significance_test(my_classifiers_scores[i], my_classifiers_scores[j], 0.10)\n",
    "        print(\"%s vs %s: %s\" % (type(my_classifiers[i]).__name__,\n",
    "                                type(my_classifiers[j]).__name__, significant))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea725c-f53a-48a6-a939-93c88a366905",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: Modeling</h4>\n",
    "\n",
    "Describe the classifiers you have chosen.\n",
    "Be sure to include all details about any parameter settings used for the algorithms.\n",
    "\n",
    "Compare the performance of your models using k-fold validation.\n",
    "You may look at accuracy, F1 or other measures.\n",
    "\n",
    "Then, briefly summarize your results.\n",
    "Are your results statistically significant?\n",
    "Is there a clear winner?\n",
    "What do the standard deviations look like, and what do they tell us about the different models?\n",
    "Include a table like Table 1.\n",
    "\n",
    "<center>Table 1: Every table needs a caption.</center>\n",
    "\n",
    "| Model | Mean Accuracy | Standard Deviation of Accuracy |\n",
    "|-------|---------------|--------------------------------|\n",
    "| Logistic Regression | 0.724 | 0.004\n",
    "| K-Nearest Neighbor | 0.750 | 0.003\n",
    "| Decision Tree | 0.655 | 0.011"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4127f125-5ddf-4bc6-a6b6-4679cb0158d1",
   "metadata": {},
   "source": [
    "# Part 4: Analysis\n",
    "\n",
    "Now, take some time to go over your results for each classifier and try to make sense of them.\n",
    " - Why do some classifiers work better than others?\n",
    " - Would another evaluation metric work better than vanilla accuracy?\n",
    " - Is there still a problem in the data that should fixed in data cleaning?\n",
    " - Does the statistical significance between the different classifiers make sense?\n",
    " - Are there parameters for the classifier that I can tweak to get better performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f6ef88-5094-4692-acad-22eb38d3713e",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: Analysis</h4>\n",
    "\n",
    "Discuss your observations, the relationship you found, and how you applied concepts from the class to this project.\n",
    "For example, you may find that some feature has the most impact in predicting your response variable or removing a feature improves the model accuracy.\n",
    "Or you may observe that your training accuracy is much higher than your test accuracy and you may want to explain what issues may arise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26983b3b-cbb1-4f7f-a15d-95f0a654b5ea",
   "metadata": {},
   "source": [
    "# Part 5: Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ecfa57-af63-472f-9041-b08bb5506fb9",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: Conclusion</h4>\n",
    "\n",
    "Briefly summarize the important results and conclusions presented in the project.\n",
    "What are the important points illustrated by your work?\n",
    "Are there any areas for further investigation or improvement?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d7f964-b4e6-4b84-a0fd-9d815f06980e",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: References</h4>\n",
    "\n",
    "Include a standard bibliography with citations referring to techniques or published papers you used throughout your report (if you used any).\n",
    "\n",
    "For example:\n",
    "```\n",
    "[1] Derpanopoulos, G. (n.d.). Bayesian Model Checking & Comparison.\n",
    "https://georgederpa.github.io/teaching/modelChecking.html.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750f6601-a2e8-4bd8-aa58-b1b4b9310454",
   "metadata": {},
   "source": [
    "# Part XC: Extra Credit\n",
    "\n",
    "So far you have used a synthetic dataset that was created just for you.\n",
    "But, data science is always more interesting when you are dealing with actual data from the real world.\n",
    "Therefore, you will have an opportunity for extra credit on this assignment using real-world data.\n",
    "\n",
    "For extra credit, repeat the **written tasks** of Parts 0 through 4 with an additional dataset that you find yourself.\n",
    "For the written portion of the extra credit for Part 0, include information about where you got the data and what the data represents.\n",
    "You may choose any dataset that represents real data (i.e., is **not** synthetic or generated)\n",
    "and is **not** [pre-packaged in scikit-learn](https://scikit-learn.org/stable/datasets.html).\n",
    "\n",
    "Below are some of the many places you can start looking for datasets:\n",
    " - [Kaggle](https://www.kaggle.com/datasets) -- Kaggle is a website focused around machine learning competitions,\n",
    "       where people compete to see who can get the best results on a dataset.\n",
    "       It is very popular in the machine learning community and has thousands of datasets with descriptions.\n",
    "       Make sure to read the dataset's description, as Kaggle also has synthetic datasets.\n",
    " - [data.gov](https://data.gov/) -- A portal for data from the US government.\n",
    "        The US government has a lot of data, and much of it has to be available to the public by law.\n",
    "        This portal contains some of the more organized data from several different government agencies.\n",
    "        In general, the government has A LOT of interesting data.\n",
    "        It may not always be clean (remember the CIA factbook), but it is interesting and available.\n",
    "        All data here should be real-world, but make sure to read the description to verify.\n",
    " - [UCI's Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets.php) -- UC Irvine has their own data repository with a few hundred datasets on many different topics.\n",
    "        Make sure to read the dataset's description, as UCI also has synthetic datasets.\n",
    " - [WHO's Global Health Observatory](https://apps.who.int/gho/data/node.home) -- The World Health Organization keeps track of many different health-related statistics for most of the countries in the world.\n",
    "        All data here should be real-world, but make sure to read the description to verify.\n",
    " - [Google's Dataset Search](https://datasetsearch.research.google.com/) -- Google indexes many datasets that can be searched here.\n",
    "\n",
    "You can even create a dataset from scratch if you find some data you like that is not already organized into a specific dataset.\n",
    "The only real distinction between \"data\" and a \"dataset\" is that a dataset is organized and finite (has a fixed size).\n",
    "\n",
    "Create a new section in your written report for this extra credit and include all the written tasks for the extra credit there.\n",
    "Each written task/section that you complete for your new dataset is eligible for extra credit (so you can still receive some extra credit even if you do not complete all parts).\n",
    "There is no need to submit any code for the extra credit.\n",
    "If you created a new dataset, include the dataset or links to it with your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
